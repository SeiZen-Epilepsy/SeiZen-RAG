{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca71591a8c2d92",
   "metadata": {},
   "source": [
    "# Notebook 1: Ingest Data dan Pra-pemrosesan untuk RAG\n",
    "\n",
    "Tujuan notebook ini adalah untuk memuat dokumen, mengekstrak teksnya, dan memecahnya menjadi potongan-potongan (chunks) yang lebih kecil agar siap untuk proses embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42050de73f7d900",
   "metadata": {},
   "source": [
    "## 1. Impor Library yang Dibutuhkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d900486a9b883d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader, UnstructuredPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3a065d483b856f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key: True\n"
     ]
    }
   ],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(f\"OpenAI API Key: {bool(openai_api_key)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aea87a56f81ca7",
   "metadata": {},
   "source": [
    "## 2. Tentukan Path ke Data dan Temukan Semua File PDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2b08c6b2731bd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "project_root = os.path.dirname(current_dir)\n",
    "data_dir = os.path.join(project_root, \"data\")\n",
    "pdf_file_names = [file for file in os.listdir(data_dir) if file.endswith(\".pdf\")]\n",
    "pdf_file_paths = [os.path.join(data_dir, file) for file in pdf_file_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f81d33a8c6f4dd",
   "metadata": {},
   "source": [
    "## 3. Muat Semua Dokumen PDF yang Ditemukan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4926cc3769540fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memuat dokumen dari: d:\\Zulfi\\CodeLabs\\SeiZen\\SeiZen-RAG\\data\\ojsadmin,+207.pdf...\n",
      "Berhasil memuat 6 halaman/bagian dari ojsadmin,+207.pdf.\n",
      "\n",
      "Memuat dokumen dari: d:\\Zulfi\\CodeLabs\\SeiZen\\SeiZen-RAG\\data\\Self-superviced Learning.pdf...\n",
      "Berhasil memuat 23 halaman/bagian dari Self-superviced Learning.pdf.\n",
      "\n",
      "Total 29 halaman/bagian berhasil dimuat dari semua file PDF.\n",
      "\n",
      "Contoh konten dari halaman pertama dokumen pertama yang dimuat:\n",
      "Indian Journal of Public Health Research & Development, March 2020, Vol. 11, No. 03  1107\n",
      "The Correlation Factors on \n",
      "Epilepsy Stigma amongst People in Indonesia\n",
      "Saniya Ashilah Rabbani1, Joseph Ekowahono R2, Viskasari P. Kalanjati3\n",
      "1Clinical Students at Faculty of Medicine, 2Lecturer at Department of Neurology, 3Lecturer at Department of \n",
      "Anatomy and Histology, General Hospital of dr. Soetomo, Faculty of Medicine, Universitas Airlangga, \n",
      "Surabaya, Indonesia\n",
      "Abstract\n",
      "Background: Epilepsy is a rec...\n",
      "Metadata contoh: {'producer': 'Adobe PDF Library 9.0', 'creator': 'Adobe InDesign CS4 (6.0)', 'creationdate': '2020-06-03T12:10:59+05:30', 'moddate': '2020-06-03T12:11:10+05:30', 'source': 'ojsadmin,+207.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1'}\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "all_loaded_documents = []\n",
    "\n",
    "if pdf_file_paths:\n",
    "    for pdf_path in pdf_file_paths:\n",
    "        try:\n",
    "            print(f\"\\nMemuat dokumen dari: {pdf_path}...\")\n",
    "            loader = PyPDFLoader(pdf_path)\n",
    "            documents_from_single_pdf = loader.load()\n",
    "\n",
    "            for doc in documents_from_single_pdf:\n",
    "                doc.metadata[\"source\"] = os.path.basename(pdf_path)\n",
    "\n",
    "            all_loaded_documents.extend(documents_from_single_pdf)\n",
    "            print(f\"Berhasil memuat {len(documents_from_single_pdf)} halaman/bagian dari {os.path.basename(pdf_path)}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saat memuat {pdf_path}: {e}\")\n",
    "\n",
    "    if all_loaded_documents:\n",
    "        print(f\"\\nTotal {len(all_loaded_documents)} halaman/bagian berhasil dimuat dari semua file PDF.\")\n",
    "        print(\"\\nContoh konten dari halaman pertama dokumen pertama yang dimuat:\")\n",
    "        print(all_loaded_documents[0].page_content[:500] + \"...\")\n",
    "        print(f\"Metadata contoh: {all_loaded_documents[0].metadata}\")\n",
    "        print(\"-\" * 30)\n",
    "else:\n",
    "    print(\"Tidak ada file PDF untuk dimuat.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b01505b105945e",
   "metadata": {},
   "source": [
    "## 4. Ekstrak Teks dari Dokumen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a28445f68c8f809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total dokumen (halaman/bagian) yang dimuat dari semua PDF: 29\n",
      "\n",
      "--- Dokumen Gabungan 1 ---\n",
      "Metadata: {'producer': 'Adobe PDF Library 9.0', 'creator': 'Adobe InDesign CS4 (6.0)', 'creationdate': '2020-06-03T12:10:59+05:30', 'moddate': '2020-06-03T12:11:10+05:30', 'source': 'ojsadmin,+207.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "--- Dokumen Gabungan 2 ---\n",
      "Metadata: {'producer': 'Adobe PDF Library 9.0', 'creator': 'Adobe InDesign CS4 (6.0)', 'creationdate': '2020-06-03T12:10:59+05:30', 'moddate': '2020-06-03T12:11:10+05:30', 'source': 'ojsadmin,+207.pdf', 'total_pages': 6, 'page': 1, 'page_label': '2'}\n",
      "\n",
      "--- Dokumen Gabungan 3 ---\n",
      "Metadata: {'producer': 'Adobe PDF Library 9.0', 'creator': 'Adobe InDesign CS4 (6.0)', 'creationdate': '2020-06-03T12:10:59+05:30', 'moddate': '2020-06-03T12:11:10+05:30', 'source': 'ojsadmin,+207.pdf', 'total_pages': 6, 'page': 2, 'page_label': '3'}\n"
     ]
    }
   ],
   "source": [
    "if all_loaded_documents:\n",
    "    print(f\"\\nTotal dokumen (halaman/bagian) yang dimuat dari semua PDF: {len(all_loaded_documents)}\")\n",
    "    for i, doc in enumerate(all_loaded_documents[:min(3, len(all_loaded_documents))]):\n",
    "        print(f\"\\n--- Dokumen Gabungan {i+1} ---\")\n",
    "        print(f\"Metadata: {doc.metadata}\")\n",
    "else:\n",
    "    print(\"Tidak ada dokumen yang berhasil dimuat.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671a7a26411f16a4",
   "metadata": {},
   "source": [
    "## 5. Memecah Teks menjadi Chunks (Text Splitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2c53dacd4f28528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total chunks yang dihasilkan dari semua PDF: 206\n",
      "\n",
      "Contoh beberapa chunk pertama (perhatikan metadatanya):\n",
      "\n",
      "--- Chunk 1 ---\n",
      "Metadata: {'producer': 'Adobe PDF Library 9.0', 'creator': 'Adobe InDesign CS4 (6.0)', 'creationdate': '2020-06-03T12:10:59+05:30', 'moddate': '2020-06-03T12:11:10+05:30', 'source': 'ojsadmin,+207.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1'}\n",
      "Konten: Indian Journal of Public Health Research & Development, March 2020, Vol. 11, No. 03  1107\n",
      "The Correlation Factors on \n",
      "Epilepsy Stigma amongst People in Indonesia\n",
      "Saniya Ashilah Rabbani1, Joseph Ekowah...\n",
      "Panjang Konten: 998 karakter\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Metadata: {'producer': 'Adobe PDF Library 9.0', 'creator': 'Adobe InDesign CS4 (6.0)', 'creationdate': '2020-06-03T12:10:59+05:30', 'moddate': '2020-06-03T12:11:10+05:30', 'source': 'ojsadmin,+207.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1'}\n",
      "Konten: many wrong assumptions and views of some Indonesian people about epilepsy disease. The study was \n",
      "conducted to find out the correlation between social factors background (domicile, age and occupation ...\n",
      "Panjang Konten: 975 karakter\n",
      "\n",
      "--- Chunk 3 ---\n",
      "Metadata: {'producer': 'Adobe PDF Library 9.0', 'creator': 'Adobe InDesign CS4 (6.0)', 'creationdate': '2020-06-03T12:10:59+05:30', 'moddate': '2020-06-03T12:11:10+05:30', 'source': 'ojsadmin,+207.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1'}\n",
      "Konten: analyzed descriptively and tested by chi-square test using SPSS.\n",
      "Result: With a total of 127 respondents based on domicile got significantcorrelation, based on last education \n",
      "level also got significa...\n",
      "Panjang Konten: 948 karakter\n"
     ]
    }
   ],
   "source": [
    "all_chunks = []\n",
    "\n",
    "if all_loaded_documents:\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "\n",
    "    for doc_idx, doc_content_obj in enumerate(all_loaded_documents):\n",
    "        if not isinstance(doc_content_obj, Document):\n",
    "            print(f\"Peringatan: Item ke-{doc_idx} bukan objek Document LangChain, melainkan {type(doc_content_obj)}. Dilewati.\")\n",
    "            continue\n",
    "\n",
    "        chunks_from_doc = text_splitter.split_text(doc_content_obj.page_content)\n",
    "\n",
    "        for chunk_text in chunks_from_doc:\n",
    "            chunk_doc = Document(page_content=chunk_text, metadata=doc_content_obj.metadata.copy())\n",
    "            all_chunks.append(chunk_doc)\n",
    "\n",
    "    print(f\"\\nTotal chunks yang dihasilkan dari semua PDF: {len(all_chunks)}\")\n",
    "\n",
    "    if all_chunks:\n",
    "        print(\"\\nContoh beberapa chunk pertama (perhatikan metadatanya):\")\n",
    "        for i, chunk in enumerate(all_chunks[:min(3, len(all_chunks))]):\n",
    "            print(f\"\\n--- Chunk {i+1} ---\")\n",
    "            print(f\"Metadata: {chunk.metadata}\")\n",
    "            print(f\"Konten: {chunk.page_content[:200]}...\")\n",
    "            print(f\"Panjang Konten: {len(chunk.page_content)} karakter\")\n",
    "else:\n",
    "    print(\"Tidak ada dokumen untuk dipecah menjadi chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a160833fa1c654",
   "metadata": {},
   "source": [
    "## 6. Menyimpan chunks untuk digunakan di notebook lain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ac04a93b417f15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chunks berhasil disimpan ke: d:\\Zulfi\\CodeLabs\\SeiZen\\SeiZen-RAG\\notebooks\\chunk_files\\processed_chunks_multi_pdf.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "if all_chunks:\n",
    "    notebooks_dir = os.path.join(project_root, \"notebooks\", \"chunk_files\")\n",
    "    os.makedirs(notebooks_dir, exist_ok=True)\n",
    "    chunks_file_path = os.path.join(notebooks_dir, \"processed_chunks_multi_pdf.pkl\")\n",
    "    try:\n",
    "        with open(chunks_file_path, \"wb\") as f:\n",
    "            pickle.dump(all_chunks, f)\n",
    "        print(f\"\\nChunks berhasil disimpan ke: {chunks_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saat menyimpan chunks: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
