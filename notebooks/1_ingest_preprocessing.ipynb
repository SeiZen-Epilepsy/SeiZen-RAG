{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Notebook 1: Ingest Data dan Pra-pemrosesan untuk RAG\n",
    "\n",
    "Tujuan notebook ini adalah untuk memuat dokumen, mengekstrak teksnya, dan memecahnya menjadi potongan-potongan (chunks) yang lebih kecil agar siap untuk proses embedding."
   ],
   "id": "ca71591a8c2d92"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Impor Library yang Dibutuhkan",
   "id": "b42050de73f7d900"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader, UnstructuredPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "d900486a9b883d13",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(f\"OpenAI API Key: {bool(openai_api_key)}\")"
   ],
   "id": "c3a065d483b856f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Tentukan Path ke Data dan Temukan Semua File PDF\n",
   "id": "c6aea87a56f81ca7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "current_dir = os.getcwd()\n",
    "project_root = os.path.dirname(current_dir)\n",
    "data_dir = os.path.join(project_root, \"data\")\n",
    "pdf_file_names = [file for file in os.listdir(data_dir) if file.endswith(\".pdf\")]\n",
    "pdf_file_paths = [os.path.join(data_dir, file) for file in pdf_file_names]"
   ],
   "id": "b2b08c6b2731bd67",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Muat Semua Dokumen PDF yang Ditemukan",
   "id": "40f81d33a8c6f4dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_loaded_documents = []\n",
    "\n",
    "if pdf_file_paths:\n",
    "    for pdf_path in pdf_file_paths:\n",
    "        try:\n",
    "            print(f\"\\nMemuat dokumen dari: {pdf_path}...\")\n",
    "            loader = PyPDFLoader(pdf_path)\n",
    "            documents_from_single_pdf = loader.load()\n",
    "\n",
    "            for doc in documents_from_single_pdf:\n",
    "                doc.metadata[\"source\"] = os.path.basename(pdf_path)\n",
    "\n",
    "            all_loaded_documents.extend(documents_from_single_pdf)\n",
    "            print(f\"Berhasil memuat {len(documents_from_single_pdf)} halaman/bagian dari {os.path.basename(pdf_path)}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saat memuat {pdf_path}: {e}\")\n",
    "\n",
    "    if all_loaded_documents:\n",
    "        print(f\"\\nTotal {len(all_loaded_documents)} halaman/bagian berhasil dimuat dari semua file PDF.\")\n",
    "        print(\"\\nContoh konten dari halaman pertama dokumen pertama yang dimuat:\")\n",
    "        print(all_loaded_documents[0].page_content[:500] + \"...\")\n",
    "        print(f\"Metadata contoh: {all_loaded_documents[0].metadata}\")\n",
    "        print(\"-\" * 30)\n",
    "else:\n",
    "    print(\"Tidak ada file PDF untuk dimuat.\")\n"
   ],
   "id": "a4926cc3769540fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Ekstrak Teks dari Dokumen\n",
   "id": "23b01505b105945e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if all_loaded_documents:\n",
    "    print(f\"\\nTotal dokumen (halaman/bagian) yang dimuat dari semua PDF: {len(all_loaded_documents)}\")\n",
    "    for i, doc in enumerate(all_loaded_documents[:min(3, len(all_loaded_documents))]):\n",
    "        print(f\"\\n--- Dokumen Gabungan {i+1} ---\")\n",
    "        print(f\"Metadata: {doc.metadata}\")\n",
    "else:\n",
    "    print(\"Tidak ada dokumen yang berhasil dimuat.\")"
   ],
   "id": "9a28445f68c8f809",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Memecah Teks menjadi Chunks (Text Splitting)",
   "id": "671a7a26411f16a4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_chunks = []\n",
    "\n",
    "if all_loaded_documents:\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "\n",
    "    for doc_idx, doc_content_obj in enumerate(all_loaded_documents):\n",
    "        if not isinstance(doc_content_obj, Document):\n",
    "            print(f\"Peringatan: Item ke-{doc_idx} bukan objek Document LangChain, melainkan {type(doc_content_obj)}. Dilewati.\")\n",
    "            continue\n",
    "\n",
    "        chunks_from_doc = text_splitter.split_text(doc_content_obj.page_content)\n",
    "\n",
    "        for chunk_text in chunks_from_doc:\n",
    "            chunk_doc = Document(page_content=chunk_text, metadata=doc_content_obj.metadata.copy())\n",
    "            all_chunks.append(chunk_doc)\n",
    "\n",
    "    print(f\"\\nTotal chunks yang dihasilkan dari semua PDF: {len(all_chunks)}\")\n",
    "\n",
    "    if all_chunks:\n",
    "        print(\"\\nContoh beberapa chunk pertama (perhatikan metadatanya):\")\n",
    "        for i, chunk in enumerate(all_chunks[:min(3, len(all_chunks))]):\n",
    "            print(f\"\\n--- Chunk {i+1} ---\")\n",
    "            print(f\"Metadata: {chunk.metadata}\")\n",
    "            print(f\"Konten: {chunk.page_content[:200]}...\")\n",
    "            print(f\"Panjang Konten: {len(chunk.page_content)} karakter\")\n",
    "else:\n",
    "    print(\"Tidak ada dokumen untuk dipecah menjadi chunks.\")"
   ],
   "id": "b2c53dacd4f28528",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Menyimpan chunks untuk digunakan di notebook lain",
   "id": "f0a160833fa1c654"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "if all_chunks:\n",
    "    notebooks_dir = os.path.join(project_root, \"notebooks\", \"chunk_files\")\n",
    "    os.makedirs(notebooks_dir, exist_ok=True)\n",
    "    chunks_file_path = os.path.join(notebooks_dir, \"processed_chunks_multi_pdf.pkl\")\n",
    "    try:\n",
    "        with open(chunks_file_path, \"wb\") as f:\n",
    "            pickle.dump(all_chunks, f)\n",
    "        print(f\"\\nChunks berhasil disimpan ke: {chunks_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saat menyimpan chunks: {e}\")\n"
   ],
   "id": "1ac04a93b417f15d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
